# Pyspark 101

Polish up your data processing skill using pyspark!

# Installation(stand alone)

[check here to install spark 3.0+](https://github.com/YLTsai0609/DataScience_Note/blob/master/spark.md)

# Marathon

| Content ID   |Date| Content | From  | Note |
|-------|----|---------|-------|------|
| 001 |  1/11|[hello_world](001_hello_world.py)  |  [spark-examples/pyspark-examples](https://github.com/spark-examples/pyspark-examples)||
| 002 |  1/12|[create_spark_session](002_create_spark_session.py)  | [How to create SparkSession](https://sparkbyexamples.com/pyspark/pyspark-what-is-sparksession/)||
| 003 |  1/12|[accumulator](003_accumulator.py)  |[Accumulator](https://sparkbyexamples.com/pyspark/pyspark-accumulator-with-example/)||
| 004 |  1/13 |[RDD](004_rdd.py)  |[RDD](https://sparkbyexamples.com/pyspark-rdd)||
| 005 |  1/13 |[Repartition() vs Coalesce()](005_repartition_coalesce.py)  |[Repartition() vs Coalesce()](https://sparkbyexamples.com/pyspark/pyspark-repartition-vs-coalesce/)||

# Terminology

* [x] rdd
* [x] repartition/coalesce
* [] spark cluster vm/multiple-host
* [] yarn
* [] mesos

# Reference

[kenttw/spark_tutorial](https://github.com/kenttw/spark_tutorial)

[spark-examples/pyspark-examples](https://github.com/spark-examples/pyspark-examples)
